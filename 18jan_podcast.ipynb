{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12RA5lCN6yRAOKYcGB5jVST4qZVBQfVTR","timestamp":1737194238709}],"authorship_tag":"ABX9TyOjUNwLL4HDrj7ac4F1PIwr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install googletrans==4.0.0-rc1\n","!pip install gTT\n","!pip install pydub\n","!pip install google-cloud-texttospeech"],"metadata":{"id":"duyDDpmYIHXa","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1737218371884,"user_tz":-330,"elapsed":15934,"user":{"displayName":"Rohan Narula","userId":"06355787263360910120"}},"outputId":"81c895ab-bb58-472d-9e8e-4addb7347b5f","collapsed":true},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting googletrans==4.0.0-rc1\n","  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n","  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.12.14)\n","Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n","Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n","Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n","Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n","Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n","Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n","Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n","Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n","  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n","Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n","Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: googletrans\n","  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=dc8de764d97c4d2d9c346d7f27158bbb7e8ba0357a9b443137896d3b74d95bb1\n","  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n","Successfully built googletrans\n","Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n","  Attempting uninstall: h11\n","    Found existing installation: h11 0.14.0\n","    Uninstalling h11-0.14.0:\n","      Successfully uninstalled h11-0.14.0\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","  Attempting uninstall: httpcore\n","    Found existing installation: httpcore 1.0.7\n","    Uninstalling httpcore-1.0.7:\n","      Successfully uninstalled httpcore-1.0.7\n","  Attempting uninstall: httpx\n","    Found existing installation: httpx 0.28.1\n","    Uninstalling httpx-0.28.1:\n","      Successfully uninstalled httpx-0.28.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","openai 1.59.6 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n","langsmith 0.2.10 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n","\u001b[31mERROR: Could not find a version that satisfies the requirement gTT (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for gTT\u001b[0m\u001b[31m\n","\u001b[0mCollecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n","Collecting google-cloud-texttospeech\n","  Downloading google_cloud_texttospeech-2.24.0-py2.py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.19.2)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (2.27.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (1.25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (4.25.5)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.66.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.32.3)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.69.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.62.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (4.9)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2024.12.14)\n","Downloading google_cloud_texttospeech-2.24.0-py2.py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.8/183.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: google-cloud-texttospeech\n","Successfully installed google-cloud-texttospeech-2.24.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"54978f8bb5cd4baf88fbe5deb2199bfb"}},"metadata":{}}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MuqNKIgHxYv","executionInfo":{"status":"ok","timestamp":1737218371885,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rohan Narula","userId":"06355787263360910120"}},"outputId":"d1f63238-d23a-4452-e9c4-fb838554c9b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["de\n"]}],"source":["from googletrans import Translator\n","\n","def detect_script_language(script):\n","    translator = Translator()\n","    try:\n","        detection = translator.detect(script)\n","        return detection.lang\n","    except Exception as e:\n","        return f\"Error in language detection: {str(e)}\"\n","script = \"Hallo, wie geht es dir?\"\n","print(detect_script_language(script))"]},{"cell_type":"code","source":["import re\n","def split_script_by_personas(script, personas):\n","\n","    # Escape and join persona names for regex\n","    personas_pattern = \"|\".join(re.escape(persona) for persona in personas)\n","\n","    # Regex pattern to match persona lines\n","    pattern = rf\"^\\s*\\**({personas_pattern})\\**:\\s*(.+)\"\n","\n","    lines = script.split(\"\\n\")\n","    dialogues = []\n","    current_persona = None\n","    current_dialogue = []\n","\n","    for line in lines:\n","        match = re.match(pattern, line)\n","        if match:\n","            # Save the previous dialogue\n","            if current_persona and current_dialogue:\n","                dialogues.append((current_persona, \" \".join(current_dialogue)))\n","\n","            # Start a new dialogue\n","            current_persona = match.group(1)\n","            current_dialogue = [match.group(2)]\n","        elif current_persona:\n","            # Append continuation lines to the current dialogue\n","            current_dialogue.append(line.strip())\n","\n","    # Add the last dialogue\n","    if current_persona and current_dialogue:\n","        dialogues.append((current_persona, \" \".join(current_dialogue)))\n","\n","    return [(persona, dialogue.replace('**', '').strip()) for persona, dialogue in dialogues]\n"],"metadata":{"id":"IVs07mWOJX7E","executionInfo":{"status":"ok","timestamp":1737218371885,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rohan Narula","userId":"06355787263360910120"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.cloud import texttospeech\n","import os\n","import random\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"key.json\"\n","\n","def generate_audio_google_cloud(text, language,i, file_path, no_of_people):\n","\n","    # Map voice_id to Google Cloud language codes\n","    lang = {\n","    'en-GB': ['en-GB-Neural2-A','en-GB-Neural2-B','en-GB-Neural2-C','en-GB-Neural2-D'],\n","    'hi-IN': ['hi-IN-Neural2-A', 'hi-IN-Neural2-B','hi-IN-Neural2-C','hi-IN-Neural2-D'],\n","    'en-AU': ['en-AU-Neural2-A','en-AU-Neural2-B', 'en-AU-Neural2-C', 'en-AU-Neural2-D'],\n","    'fr-FR': ['fr-FR-Neural2-A', 'fr-FR-Neural2-B','fr-FR-Neural2-C','fr-FR-Neural2-D'],  # French\n","    'es-ES': ['es-ES-Neural2-A', 'es-ES-Neural2-B','es-ES-Neural2-C','es-ES-Neural2-D']  # Spanish\n","}\n","    lang_code = {\n","    'English': ['en-GB','en-AU'],\n","    'Hindi': ['hi-IN'],\n","    'French': ['fr-FR'],  # French\n","    'Spanish': ['es-ES']  # Spanish\n","}\n","    if language not in lang_code:\n","        raise ValueError(f\"Unsupported voice_id: {language}. Supported options: {list(lang.keys())}\")\n","\n","    # Initialize the TTS client\n","    client = texttospeech.TextToSpeechClient()\n","    audio_config = texttospeech.AudioConfig(\n","        audio_encoding=texttospeech.AudioEncoding.MP3,\n","        speaking_rate=1  # Set speaking rate\n","    )\n","    random_language_code = random.choice(lang_code[language])\n","    # Set the input text\n","    input_text = texttospeech.SynthesisInput(text=text)\n","    n = no_of_people\n","    # Set the voice parameters\n","    voice = texttospeech.VoiceSelectionParams(\n","        language_code=random_language_code,  # Use the selected language\n","         name=lang[random_language_code][i%n]\n","    )\n","\n","    # Set the audio output configuration\n","    audio_config = texttospeech.AudioConfig(\n","        audio_encoding=texttospeech.AudioEncoding.MP3  # Save as MP3\n","    )\n","\n","    # Generate the audio\n","    response = client.synthesize_speech(\n","        input=input_text, voice=voice, audio_config=audio_config\n","    )\n","\n","    # Save the audio to the specified file\n","    with open(file_path, \"wb\") as out:\n","        out.write(response.audio_content)\n","\n","    return f\"Audio file generated at {file_path}\"\n"],"metadata":{"id":"Z7eDG5LKPN_a","executionInfo":{"status":"ok","timestamp":1737218372883,"user_tz":-330,"elapsed":1005,"user":{"displayName":"Rohan Narula","userId":"06355787263360910120"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from pydub import AudioSegment\n","def create_podcast_audio(script, personas):\n","    try:\n","        lines = split_script_by_personas(script, personas)\n","        print(lines)\n","        audio_clips = []\n","        language_code = detect_script_language(script)\n","        print(language_code)\n","        m = {\n","              'en': 'English',\n","              'hi': 'Hindi',\n","              'fr': 'French',  # French\n","              'es': 'Spanish'  # Spanish\n","            }\n","        language = m[language_code]\n","        for i, (persona, dialogue) in enumerate(lines):\n","            output_path = f\"voice_{i}.mp3\"\n","            generate_audio_google_cloud(dialogue, language,i, output_path, 2)\n","            audio_clips.append(AudioSegment.from_file(output_path))\n","\n","        final_audio = AudioSegment.empty()\n","        for clip in audio_clips:\n","            final_audio += clip\n","\n","        final_audio.export(\"podcast_output.mp3\", format=\"mp3\")\n","        print(\"Podcast saved as podcast_output.mp3\")\n","        return \"podcast_output.mp3\"\n","    except Exception as e:\n","        print(f\"Audio generation error: {str(e)}\")\n","        return None\n"],"metadata":{"id":"EI3VJMRsQfXI","executionInfo":{"status":"ok","timestamp":1737218372883,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rohan Narula","userId":"06355787263360910120"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["script = \"\"\"\n","Alice: नमस्ते और स्वागत है The AI Edge में! मैं हूं Alice।\n","\n","Bob: और मैं हूं Bob। आज हम एक रोमांचक विषय पर चर्चा करेंगे: स्टॉक मार्केट पर आर्टिफिशियल इंटेलिजेंस का प्रभाव। AI हर इंडस्ट्री को बदल रहा है, और फाइनेंशियल वर्ल्ड भी इससे अछूता नहीं है।\n","\n","Alice: सही कहा, Bob। हाल के सालों में स्टॉक मार्केट में AI का उपयोग काफी बढ़ गया है। अल्गोरिदमिक ट्रेडिंग से लेकर सेंटिमेंट एनालिसिस तक, AI यह तय करने के तरीके को पूरी तरह बदल रहा है कि निवेश कैसे किया जाए और पैसा कैसे प्रवाहित हो। चलिए शुरुआत करते हैं अल्गोरिदमिक ट्रेडिंग से।\n","\n","Bob: बिल्कुल! अल्गोरिदमिक ट्रेडिंग या अल्गो-ट्रेडिंग, स्टॉक मार्केट में AI का सबसे बड़ा उपयोग है। AI-आधारित एल्गोरिदम पहले से तय मानदंडों जैसे प्राइस, वॉल्यूम, या जटिल पैटर्न के आधार पर ट्रेडिंग को तेज़ी से अंजाम देते हैं।\n","\n","Alice: और इनकी गति अद्भुत होती है—ये एल्गोरिदम लाखों डेटा पॉइंट्स को सेकंड के भीतर एनालाइज़ करके ट्रेड्स कर सकते हैं। यह संस्थागत निवेशकों को रिटेल ट्रेडर्स के मुकाबले एक बड़ा फायदा देता है।\n","\n","Bob: सही कहा, लेकिन इसका एक नकारात्मक पहलू भी है। ये हाई-फ्रीक्वेंसी ट्रेडिंग सिस्टम कभी-कभी मार्केट में अस्थिरता ला सकते हैं। 2010 के “फ्लैश क्रैश” को याद है?\n","\n","Alice: बिल्कुल। उस घटना ने दिखाया कि बिना उचित निगरानी के एल्गोरिदम मार्केट वोलाटिलिटी को बढ़ा सकते हैं। यह याद दिलाता है कि AI पर पूरी तरह निर्भर नहीं हुआ जा सकता—इसे अभी भी मानव हस्तक्षेप की ज़रूरत है।\n","\n","Alice: AI का एक और दिलचस्प उपयोग है सेंटिमेंट एनालिसिस। मशीन लर्निंग और नैचुरल लैंग्वेज प्रोसेसिंग का उपयोग करके AI न्यूज़ आर्टिकल्स, सोशल मीडिया और यहां तक कि अर्निंग्स कॉल ट्रांसक्रिप्ट्स का विश्लेषण कर सकता है ताकि मार्केट सेंटिमेंट को समझा जा सके।\n","\n","Bob: यह वाकई कमाल है। सोचो, अगर AI ट्विटर पर ब्रेकिंग न्यूज़ या ट्रेंड्स को स्कैन कर सके। अगर Elon Musk टेस्ला के बारे में ट्वीट करते हैं, तो AI सिस्टम तुरंत उस सेंटिमेंट को एनालाइज़ करके इन्वेस्टमेंट स्ट्रैटेजी में बदलाव कर सकता है।\n","\n","Alice: सही कहा! लेकिन जहां यह ट्रेडर्स को बढ़त देता है, वहीं यह कुछ नैतिक चिंताएं भी पैदा करता है। जैसे, अगर AI झूठी खबरों या पक्षपातपूर्ण जानकारी को बढ़ावा देने लगे तो क्या होगा?\n","\n","Bob: यह एक महत्वपूर्ण मुद्दा है। चुनौती यह है कि इन सिस्टम्स को विश्वसनीय डेटा पर प्रशिक्षित किया जाए और उनके निर्णय लेने के तरीके पारदर्शी हों।\n","\"\"\"\n","\n","personas = [\"Bob\", \"Alice\"]\n","create_podcast_audio(script, personas)"],"metadata":{"id":"b8LKQCs21-bH","executionInfo":{"status":"ok","timestamp":1737218384067,"user_tz":-330,"elapsed":11186,"user":{"displayName":"Rohan Narula","userId":"06355787263360910120"}},"outputId":"c50790b0-992f-4017-a77c-6b391d1aa065","colab":{"base_uri":"https://localhost:8080/","height":110}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Alice', 'नमस्ते और स्वागत है The AI Edge में! मैं हूं Alice।'), ('Bob', 'और मैं हूं Bob। आज हम एक रोमांचक विषय पर चर्चा करेंगे: स्टॉक मार्केट पर आर्टिफिशियल इंटेलिजेंस का प्रभाव। AI हर इंडस्ट्री को बदल रहा है, और फाइनेंशियल वर्ल्ड भी इससे अछूता नहीं है।'), ('Alice', 'सही कहा, Bob। हाल के सालों में स्टॉक मार्केट में AI का उपयोग काफी बढ़ गया है। अल्गोरिदमिक ट्रेडिंग से लेकर सेंटिमेंट एनालिसिस तक, AI यह तय करने के तरीके को पूरी तरह बदल रहा है कि निवेश कैसे किया जाए और पैसा कैसे प्रवाहित हो। चलिए शुरुआत करते हैं अल्गोरिदमिक ट्रेडिंग से।'), ('Bob', 'बिल्कुल! अल्गोरिदमिक ट्रेडिंग या अल्गो-ट्रेडिंग, स्टॉक मार्केट में AI का सबसे बड़ा उपयोग है। AI-आधारित एल्गोरिदम पहले से तय मानदंडों जैसे प्राइस, वॉल्यूम, या जटिल पैटर्न के आधार पर ट्रेडिंग को तेज़ी से अंजाम देते हैं।'), ('Alice', 'और इनकी गति अद्भुत होती है—ये एल्गोरिदम लाखों डेटा पॉइंट्स को सेकंड के भीतर एनालाइज़ करके ट्रेड्स कर सकते हैं। यह संस्थागत निवेशकों को रिटेल ट्रेडर्स के मुकाबले एक बड़ा फायदा देता है।'), ('Bob', 'सही कहा, लेकिन इसका एक नकारात्मक पहलू भी है। ये हाई-फ्रीक्वेंसी ट्रेडिंग सिस्टम कभी-कभी मार्केट में अस्थिरता ला सकते हैं। 2010 के “फ्लैश क्रैश” को याद है?'), ('Alice', 'बिल्कुल। उस घटना ने दिखाया कि बिना उचित निगरानी के एल्गोरिदम मार्केट वोलाटिलिटी को बढ़ा सकते हैं। यह याद दिलाता है कि AI पर पूरी तरह निर्भर नहीं हुआ जा सकता—इसे अभी भी मानव हस्तक्षेप की ज़रूरत है।'), ('Alice', 'AI का एक और दिलचस्प उपयोग है सेंटिमेंट एनालिसिस। मशीन लर्निंग और नैचुरल लैंग्वेज प्रोसेसिंग का उपयोग करके AI न्यूज़ आर्टिकल्स, सोशल मीडिया और यहां तक कि अर्निंग्स कॉल ट्रांसक्रिप्ट्स का विश्लेषण कर सकता है ताकि मार्केट सेंटिमेंट को समझा जा सके।'), ('Bob', 'यह वाकई कमाल है। सोचो, अगर AI ट्विटर पर ब्रेकिंग न्यूज़ या ट्रेंड्स को स्कैन कर सके। अगर Elon Musk टेस्ला के बारे में ट्वीट करते हैं, तो AI सिस्टम तुरंत उस सेंटिमेंट को एनालाइज़ करके इन्वेस्टमेंट स्ट्रैटेजी में बदलाव कर सकता है।'), ('Alice', 'सही कहा! लेकिन जहां यह ट्रेडर्स को बढ़त देता है, वहीं यह कुछ नैतिक चिंताएं भी पैदा करता है। जैसे, अगर AI झूठी खबरों या पक्षपातपूर्ण जानकारी को बढ़ावा देने लगे तो क्या होगा?'), ('Bob', 'यह एक महत्वपूर्ण मुद्दा है। चुनौती यह है कि इन सिस्टम्स को विश्वसनीय डेटा पर प्रशिक्षित किया जाए और उनके निर्णय लेने के तरीके पारदर्शी हों।')]\n","hi\n","Podcast saved as podcast_output.mp3\n"]},{"output_type":"execute_result","data":{"text/plain":["'podcast_output.mp3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]}]}